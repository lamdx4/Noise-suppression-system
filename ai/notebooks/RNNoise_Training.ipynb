{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# RNNoise PyTorch - Vietnamese Speech Enhancement\n",
                "\n",
                "**Project:** Speech-Enhancement/ai/rnnoise-pytorch\n",
                "\n",
                "**Goal:** Train RNNoise model for Vietnamese speech denoising (ESP32 deployment)\n",
                "\n",
                "---\n",
                "\n",
                "## Setup Steps:\n",
                "1. Mount Google Drive\n",
                "2. Build C tools (dump_features)\n",
                "3. Generate training data (.f32)\n",
                "4. Train PyTorch model\n",
                "5. Evaluate quality\n",
                "6. Export to C for ESP32\n",
                "\n",
                "**Note:** Prepare dataset first (VIVOS + DNS noise) and upload to Drive!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "setup"
            },
            "source": [
                "## 1. Mount Drive & Setup Paths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "mount"
            },
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "import os\n",
                "\n",
                "# Mount Drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Project paths (s·ª≠a l·∫°i cho ƒë√∫ng folder c·ªßa b·∫°n)\n",
                "PROJECT_ROOT = '/content/drive/MyDrive/Speech-Enhancement'\n",
                "AI_DIR = os.path.join(PROJECT_ROOT, 'ai')\n",
                "\n",
                "# Key directories\n",
                "RNNOISE_DIR = os.path.join(AI_DIR, 'rnnoise-pytorch')\n",
                "REFERENCE_DIR = os.path.join(AI_DIR, 'references', 'rnnoise')\n",
                "DATA_DIR = os.path.join(AI_DIR, 'data')\n",
                "LOGS_DIR = os.path.join(AI_DIR, 'logs')\n",
                "PLOTS_DIR = os.path.join(AI_DIR, 'plots')\n",
                "\n",
                "# Create directories\n",
                "for d in [DATA_DIR, LOGS_DIR, PLOTS_DIR]:\n",
                "    os.makedirs(d, exist_ok=True)\n",
                "\n",
                "print(f\"‚úÖ Project root: {PROJECT_ROOT}\")\n",
                "print(f\"‚úÖ RNNoise dir: {RNNOISE_DIR}\")\n",
                "print(f\"‚úÖ GPU: {!nvidia-smi -L}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "install"
            },
            "source": [
                "## 2. Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "deps"
            },
            "outputs": [],
            "source": [
                "%cd {RNNOISE_DIR}\n",
                "\n",
                "# Install Python packages\n",
                "!pip install -q torch>=2.0.0 numpy tqdm pyyaml\n",
                "!pip install -q pesq pystoi scipy soundfile librosa matplotlib\n",
                "\n",
                "# Install build tools for C compilation\n",
                "!apt-get update -qq && apt-get install -y -qq autoconf automake libtool build-essential sox\n",
                "\n",
                "print(\"‚úÖ Dependencies installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "build"
            },
            "source": [
                "## 3. Build C Tools (dump_features)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "build_c"
            },
            "outputs": [],
            "source": [
                "%cd {REFERENCE_DIR}\n",
                "\n",
                "# Build from source\n",
                "!chmod +x autogen.sh configure\n",
                "!./autogen.sh\n",
                "!./configure\n",
                "!make clean\n",
                "!make\n",
                "\n",
                "# Verify\n",
                "if os.path.exists('dump_features'):\n",
                "    print(\"‚úÖ dump_features built successfully!\")\n",
                "    !ls -lh dump_features\n",
                "else:\n",
                "    print(\"‚ùå Build failed! Check errors above.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "verify"
            },
            "source": [
                "## 4. Verify Dataset\n",
                "\n",
                "**Requirements:**\n",
                "- `clean_speech.pcm` - Vietnamese speech (2+ GB)\n",
                "- `background_noise.pcm` - DNS noise (20+ GB)\n",
                "- `foreground_noise.pcm` - Transient sounds (100+ MB)\n",
                "\n",
                "**Format:** 48kHz, mono, 16-bit PCM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "check_data"
            },
            "outputs": [],
            "source": [
                "# Check if dataset files exist\n",
                "speech_pcm = os.path.join(DATA_DIR, 'clean_speech.pcm')\n",
                "bg_noise_pcm = os.path.join(DATA_DIR, 'background_noise.pcm')\n",
                "fg_noise_pcm = os.path.join(DATA_DIR, 'foreground_noise.pcm')\n",
                "\n",
                "for name, path in [(\"Clean speech\", speech_pcm), \n",
                "                   (\"Background noise\", bg_noise_pcm),\n",
                "                   (\"Foreground noise\", fg_noise_pcm)]:\n",
                "    if os.path.exists(path):\n",
                "        size_mb = os.path.getsize(path) / (1024**2)\n",
                "        print(f\"‚úÖ {name}: {size_mb:.1f} MB\")\n",
                "    else:\n",
                "        print(f\"‚ùå {name}: NOT FOUND! Upload to {DATA_DIR}/\")\n",
                "\n",
                "# Optional: Test playback (first 1 second)\n",
                "# !play -r 48000 -c 1 -b 16 -e signed-integer \"{speech_pcm}\" trim 0 1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "features"
            },
            "source": [
                "## 5. Generate Training Features\n",
                "\n",
                "**This will take ~30-60 minutes for 30K sequences**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "gen_features"
            },
            "outputs": [],
            "source": [
                "%cd {REFERENCE_DIR}\n",
                "\n",
                "# Output file\n",
                "features_f32 = 'features_vn_30k.f32'\n",
                "num_sequences = 30000\n",
                "\n",
                "# Generate features\n",
                "!./dump_features \\\n",
                "    \"{speech_pcm}\" \\\n",
                "    \"{bg_noise_pcm}\" \\\n",
                "    \"{fg_noise_pcm}\" \\\n",
                "    \"{features_f32}\" \\\n",
                "    {num_sequences}\n",
                "\n",
                "# Verify output\n",
                "if os.path.exists(features_f32):\n",
                "    size_gb = os.path.getsize(features_f32) / (1024**3)\n",
                "    print(f\"\\n‚úÖ Generated: {features_f32}\")\n",
                "    print(f\"   Size: {size_gb:.2f} GB\")\n",
                "    print(f\"   Sequences: {num_sequences}\")\n",
                "else:\n",
                "    print(\"‚ùå Feature generation failed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "train"
            },
            "source": [
                "## 6. Train RNNoise Model\n",
                "\n",
                "**Parameters:**\n",
                "- GRU size: 384 (vs default 256)\n",
                "- Sparsification: 50% (for ESP32)\n",
                "- Epochs: 150\n",
                "- Batch size: 128\n",
                "\n",
                "**Expected time:** ~6-8 hours on T4 GPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "train_model"
            },
            "outputs": [],
            "source": [
                "%cd {RNNOISE_DIR}\n",
                "\n",
                "# Training command\n",
                "!python scripts/train.py \\\n",
                "    ../references/rnnoise/features_vn_30k.f32 \\\n",
                "    ./output_colab \\\n",
                "    --sparse \\\n",
                "    --epochs 150 \\\n",
                "    --gru-size 384 \\\n",
                "    --batch-size 128 \\\n",
                "    --lr 1e-3 \\\n",
                "    --lr-decay 5e-5 \\\n",
                "    --gamma 0.25 \\\n",
                "    --log-dir ../logs \\\n",
                "    --experiment-name rnnoise_vn_colab\n",
                "\n",
                "print(\"\\n‚úÖ Training complete!\")\n",
                "print(\"   Checkpoints: output_colab/checkpoints/\")\n",
                "print(\"   Logs: ../logs/\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "plot"
            },
            "source": [
                "## 7. Plot Training Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "plot_results"
            },
            "outputs": [],
            "source": [
                "%cd {RNNOISE_DIR}\n",
                "\n",
                "# Find latest metrics file\n",
                "import glob\n",
                "metrics_files = glob.glob(f\"{LOGS_DIR}/rnnoise_vn_colab_*_metrics.json\")\n",
                "\n",
                "if metrics_files:\n",
                "    latest_metrics = sorted(metrics_files)[-1]\n",
                "    print(f\"Using: {latest_metrics}\")\n",
                "    \n",
                "    # Generate plots\n",
                "    !python scripts/plot_training.py \\\n",
                "        \"{latest_metrics}\" \\\n",
                "        \"{PLOTS_DIR}\"\n",
                "    \n",
                "    # Display\n",
                "    from IPython.display import Image, display\n",
                "    display(Image(f\"{PLOTS_DIR}/loss_curves.png\"))\n",
                "    display(Image(f\"{PLOTS_DIR}/convergence.png\"))\n",
                "else:\n",
                "    print(\"‚ùå No metrics files found!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "eval"
            },
            "source": [
                "## 8. Evaluate Model Quality\n",
                "\n",
                "**Requires test dataset (noisy/ and clean/ folders)**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "evaluate"
            },
            "outputs": [],
            "source": [
                "%cd {RNNOISE_DIR}\n",
                "\n",
                "# Path to test data\n",
                "test_dir = os.path.join(AI_DIR, 'test_data')\n",
                "eval_dir = os.path.join(AI_DIR, 'evaluation')\n",
                "\n",
                "# Find best checkpoint\n",
                "checkpoints = glob.glob('output_colab/checkpoints/rnnoise_*.pth')\n",
                "if checkpoints:\n",
                "    # Use checkpoint 145 (usually best) or final\n",
                "    best_ckpt = 'output_colab/checkpoints/rnnoise_145.pth' \\\n",
                "                if os.path.exists('output_colab/checkpoints/rnnoise_145.pth') \\\n",
                "                else sorted(checkpoints)[-1]\n",
                "    \n",
                "    print(f\"Evaluating: {best_ckpt}\")\n",
                "    \n",
                "    # Run evaluation\n",
                "    !python scripts/evaluate.py \\\n",
                "        \"{best_ckpt}\" \\\n",
                "        \"{test_dir}\" \\\n",
                "        \"{eval_dir}\" \\\n",
                "        --num-samples 20\n",
                "    \n",
                "    # Show results\n",
                "    results_file = os.path.join(eval_dir, 'evaluation_results.json')\n",
                "    if os.path.exists(results_file):\n",
                "        with open(results_file) as f:\n",
                "            results = json.load(f)\n",
                "            print(\"\\nüìä Quality Metrics:\")\n",
                "            for metric, values in results['average_metrics'].items():\n",
                "                print(f\"  {metric.upper()}: {values['mean']:.3f} ¬± {values['std']:.3f}\")\n",
                "else:\n",
                "    print(\"‚ùå No checkpoints found!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "export"
            },
            "source": [
                "## 9. Export to C for ESP32"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "export_c"
            },
            "outputs": [],
            "source": [
                "%cd {RNNOISE_DIR}\n",
                "\n",
                "# Export best checkpoint\n",
                "export_dir = './exported_c'\n",
                "\n",
                "!python scripts/export_to_c.py \\\n",
                "    --quantize \\\n",
                "    \"{best_ckpt}\" \\\n",
                "    \"{export_dir}\"\n",
                "\n",
                "# Verify output\n",
                "c_file = os.path.join(export_dir, 'rnnoise_data.c')\n",
                "h_file = os.path.join(export_dir, 'rnnoise_data.h')\n",
                "\n",
                "if os.path.exists(c_file) and os.path.exists(h_file):\n",
                "    c_size = os.path.getsize(c_file) / 1024\n",
                "    print(f\"\\n‚úÖ Export complete!\")\n",
                "    print(f\"   C file: {c_size:.0f} KB\")\n",
                "    print(f\"   Location: {export_dir}/\")\n",
                "else:\n",
                "    print(\"‚ùå Export failed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "download"
            },
            "source": [
                "## 10. Download Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "download_files"
            },
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "import zipfile\n",
                "\n",
                "# Zip export files\n",
                "zip_path = '/content/rnnoise_esp32.zip'\n",
                "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
                "    zipf.write(os.path.join(export_dir, 'rnnoise_data.c'), 'rnnoise_data.c')\n",
                "    zipf.write(os.path.join(export_dir, 'rnnoise_data.h'), 'rnnoise_data.h')\n",
                "\n",
                "# Zip plots\n",
                "plots_zip = '/content/training_plots.zip'\n",
                "with zipfile.ZipFile(plots_zip, 'w') as zipf:\n",
                "    for plot in glob.glob(f\"{PLOTS_DIR}/*.png\"):\n",
                "        zipf.write(plot, os.path.basename(plot))\n",
                "\n",
                "# Download\n",
                "print(\"Downloading files...\")\n",
                "files.download(zip_path)\n",
                "files.download(plots_zip)\n",
                "\n",
                "print(\"\\n‚úÖ All done! Files downloaded.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "summary"
            },
            "source": [
                "---\n",
                "\n",
                "## Summary\n",
                "\n",
                "**Outputs:**\n",
                "- ‚úÖ Trained model: `output_colab/checkpoints/rnnoise_*.pth`\n",
                "- ‚úÖ C files: `exported_c/rnnoise_data.{c,h}`\n",
                "- ‚úÖ Training plots: `plots/*.png`\n",
                "- ‚úÖ Quality metrics: `evaluation/evaluation_results.json`\n",
                "\n",
                "**Next steps:**\n",
                "1. Integrate C files into ESP32 project\n",
                "2. Test on actual hardware\n",
                "3. Fine-tune if needed\n",
                "\n",
                "**Model specs:**\n",
                "- Size: ~850 KB (sparse + quantized)\n",
                "- Latency: ~5-10 ms per frame\n",
                "- RAM: ~800 KB\n",
                "- Real-time: ‚úÖ Yes (10ms frames)\n",
                "\n",
                "---\n",
                "\n",
                "**Documentation:** `ai/docs/context/rnnoise-pytorch-complete.md`"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
