# RNNoise Inference Flow - Gi·∫£i Th√≠ch T·ª´ng B∆∞·ªõc

Hi·ªÉu c√°ch RNNoise x·ª≠ l√Ω √¢m thanh real-time, t·∫≠p trung v√†o CONCEPT thay v√¨ code.

---

## Big Picture

RNNoise kh√¥ng "v·∫Ω l·∫°i" audio s·∫°ch t·ª´ ƒë·∫ßu nh∆∞ U-Net. Thay v√†o ƒë√≥:

**Chi·∫øn l∆∞·ª£c:** ƒêi·ªÅu ch·ªânh √¢m l∆∞·ª£ng t·ª´ng d·∫£i t·∫ßn s·ªë

- D·∫£i c√≥ nhi·ªÅu speech ‚Üí gi·ªØ nguy√™n (gain ~1.0)
- D·∫£i c√≥ nhi·ªÅu noise ‚Üí gi·∫£m xu·ªëng (gain ~0.6-0.8)

**Processing:** 10ms m·ªôt frame (480 samples @ 48kHz)

---

## 10 B∆∞·ªõc X·ª≠ L√Ω

### **B∆∞·ªõc 1: L·ªçc Cao T·∫ßn (High-Pass Filter)**

**L√†m g√¨:** B·ªè c√°c t·∫ßn s·ªë c·ª±c th·∫•p (<100-200 Hz)

**T·∫°i sao:**

- Lo·∫°i DC offset (t√≠n hi·ªáu kh√¥ng dao ƒë·ªông)
- B·ªè rumble (ti·∫øng rung c·ª±c th·∫•p t·ª´ thi·∫øt b·ªã)
- Gi·ªëng nh∆∞ bass cut tr√™n mixer

**K·∫øt qu·∫£:** Audio "s·∫°ch" h∆°n ·ªü d·∫£i th·∫•p, chu·∫©n b·ªã cho FFT

---

### **B∆∞·ªõc 2: Chia C·ª≠a S·ªï (Windowing)**

**L√†m g√¨:** Nh√¢n audio v·ªõi "c·ª≠a s·ªï" Hamming

**T·∫°i sao:**

- FFT gh√©t "c·∫°nh s·∫Øc" (ƒë·∫ßu/cu·ªëi frame)
- C·ª≠a s·ªï l√†m m∆∞·ª£t 2 ƒë·∫ßu ‚Üí gi·∫£m artifacts
- Overlap 50% (frame n√†y ch·ªìng l√™n frame tr∆∞·ªõc)

**H√¨nh dung:**

```
Hamming window: ‚ï±‚Äæ‚Äæ‚Äæ‚Äæ‚ï≤
Audio g·ªëc:     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Sau nh√¢n:      ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ
               ‚Üë M∆∞·ª£t h∆°n
```

**K·∫øt qu·∫£:** Audio c√≥ bi√™n m∆∞·ª£t, FFT ch√≠nh x√°c h∆°n

---

### **B∆∞·ªõc 3: FFT - Chuy·ªÉn Sang Mi·ªÅn T·∫ßn S·ªë**

**L√†m g√¨:** Bi·∫øn 480 samples time-domain ‚Üí 241 frequency bins

**T·∫°i sao:**

- Noise v√† speech c√≥ "d·∫•u v√¢n tay" kh√°c nhau ·ªü frequency domain
- D·ªÖ thao t√°c t·ª´ng t·∫ßn s·ªë ri√™ng bi·ªát
- Gi·ªëng nh∆∞ "xem m√†u s·∫Øc" thay v√¨ "nghe √¢m thanh"

**Output:** 241 bins ph·ªß 0-24kHz (m·ªói bin ~100 Hz)

---

### **B∆∞·ªõc 4: T√¨m Pitch (Cao ƒê·ªô Gi·ªçng N√≥i)**

**L√†m g√¨:** Ph√¢n t√≠ch autocorrelation ƒë·ªÉ t√¨m chu k·ª≥ l·∫∑p

**T·∫°i sao:**

- Gi·ªçng n√≥i = c√≥ harmonic (s√≥ng tu·∫ßn ho√†n)
- Noise = kh√¥ng c√≥ pattern l·∫∑p
- Bi·∫øt pitch ‚Üí ph√¢n bi·ªát speech vs noise t·ªët h∆°n

**K·ªπ thu·∫≠t:**

- T√¨m delay l√†m signal t·ª± t∆∞∆°ng quan cao nh·∫•t
- Delay ƒë√≥ = pitch period (chu k·ª≥)
- T·∫°o "b·∫£n sao pitch-shifted" ƒë·ªÉ d√πng sau

**K·∫øt qu·∫£:** Bi·∫øt gi·ªçng n√≥i ƒëang ·ªü t·∫ßn s·ªë n√†o (94-3000 Hz)

---

### **B∆∞·ªõc 5: Tr√≠ch Xu·∫•t 42 Features**

**L√†m g√¨:** N√©n 241 bins ‚Üí 42 s·ªë th√¥ng minh

ƒê√¢y l√† b∆∞·ªõc **SI√äU QUAN TR·ªåNG** - s·ª± kh√°c bi·ªát l·ªõn nh·∫•t v·ªõi U-Net!

#### **5a. Band Energy (22 features)**

**Concept:** Nh√≥m t·∫ßn s·ªë theo "Bark scale" (theo tai ng∆∞·ªùi nghe)

```
Tai ng∆∞·ªùi KH√îNG nghe ƒë·ªÅu:
- D·∫£i th·∫•p (0-500 Hz): Nh·∫°y c·∫£m, chia nh·ªè
- D·∫£i cao (8-24 kHz): √çt nh·∫°y, g·ªôp l·∫°i

Bark bands: [0-100Hz], [100-200Hz], [200-300Hz]...
            (nh·ªè ·ªü th·∫•p)
            [8K-10K], [10K-16K], [16K-24K]
            (to ·ªü cao)
```

**K·∫øt qu·∫£:** 241 bins ‚Üí 22 energy values (theo perception)

#### **5b. Spectral Correlation (6 features)**

**Concept:** So s√°nh frame hi·ªán t·∫°i v·ªõi 6 frames tr∆∞·ªõc

**T·∫°i sao:**

- Speech: Pattern l·∫∑p ƒë·ªÅu (phonemes ~100ms)
- Noise: Random, correlation th·∫•p

**T√≠nh to√°n:** `correlation(frame_now, frame_6ms_ago)`, `correlation(frame_now, frame_12ms_ago)`...

**K·∫øt qu·∫£:** 6 s·ªë ƒëo "temporal consistency"

#### **5c. Delta Features (7 features)**

**Concept:** T·ªëc ƒë·ªô thay ƒë·ªïi energy

**T·∫°i sao:**

- Speech: NƒÉng l∆∞·ª£ng thay ƒë·ªïi smooth (√¢m ti·∫øt)
- Noise: Thay ƒë·ªïi ƒë·ªôt ng·ªôt ho·∫∑c kh√¥ng ƒë·ªïi

**T√≠nh to√°n:** `delta = energy_now - energy_previous`

**K·∫øt qu·∫£:** 7 s·ªë ƒëo dynamics

#### **5d. Pitch Features (7 features)**

**Concept:** Th√¥ng tin v·ªÅ harmonic structure

Bao g·ªìm:

- Pitch period (chu k·ª≥)
- Pitch gain (ƒë·ªô m·∫°nh harmonic)
- Pitch correlation values

**K·∫øt qu·∫£:** 7 s·ªë m√¥ t·∫£ c·∫•u tr√∫c harmonic

**T·ªîNG: 22 + 6 + 7 + 7 = 42 features**

**Magic:** 42 features n√†y l√† **expert knowledge** ƒë∆∞·ª£c m√£ h√≥a th√†nh s·ªë!

---

### **B∆∞·ªõc 6: GRU Inference - Tr√≠ Tu·ªá Nh√¢n T·∫°o**

**L√†m g√¨:** ƒê∆∞a 42 features v√†o neural network ‚Üí ra 22 gains

**Architecture hi·ªÉu ƒë∆°n gi·∫£n:**

```
42 features ‚Üí Conv layers (filter patterns)
           ‚Üí GRU layer 1 (nh·ªõ qu√° kh·ª© 1)
           ‚Üí GRU layer 2 (nh·ªõ qu√° kh·ª© 2)
           ‚Üí GRU layer 3 (nh·ªõ qu√° kh·ª© 3)
           ‚Üí Dense layer ‚Üí 22 gains [0.6-1.0]
                        ‚Üí 1 VAD [0-1]
```

**GRU l√†m g√¨:** Nh·ªõ context t·ª´ frames tr∆∞·ªõc

- "Frame tr∆∞·ªõc c√≥ ti·∫øng ng∆∞·ªùi ‚Üí frame n√†y c≈©ng likely c√≥"
- "3 frames tr∆∞·ªõc ƒëang tƒÉng d·∫ßn ‚Üí ƒë√¢y l√† start c·ªßa phoneme"

**Output:**

- 22 gains: M·ªói band n√™n gi·∫£m bao nhi√™u
- 1 VAD: X√°c su·∫•t c√≥ gi·ªçng n√≥i (0=silence, 1=speech)

**T·∫°i sao GRU m·∫°nh:** Hi·ªÉu temporal context, kh√¥ng ch·ªâ nh√¨n 1 frame ri√™ng l·∫ª

---

### **B∆∞·ªõc 7: Pitch Filtering - Enhancement**

**L√†m g√¨:** Th√™m l·∫°i harmonic structure

**Concept:**

- T·ª´ b∆∞·ªõc 4 c√≥ "pitch-shifted spectrum"
- C·ªông c√°i n√†y v√†o spectrum hi·ªán t·∫°i v·ªõi tr·ªçng s·ªë nh·ªè
- L√†m **n·ªïi b·∫≠t** c√°c t·∫ßn s·ªë harmonic c·ªßa speech

**T·∫°i sao:**

- Speech quality kh√¥ng ch·ªâ l√† "b·ªè noise"
- C·∫ßn "enhance speech" (l√†m r√µ h∆°n)
- Harmonic = hallmark c·ªßa gi·ªçng n√≥i t·ªët

**K·∫øt qu·∫£:** Speech c√≥ "ch·∫•t" t·ª± nhi√™n h∆°n, kh√¥ng kh√¥ khan

---

### **B∆∞·ªõc 8: Gain Smoothing - L√†m M·ªãn**

**L√†m g√¨:** Kh√¥ng cho gains thay ƒë·ªïi qu√° nhanh

**T·∫°i sao:**

- Gain nh·∫£y ƒë·ªôt ng·ªôt = "musical noise" (artifacts)
- C·∫ßn smooth temporal transition

**Chi·∫øn l∆∞·ª£c:**

```
Gain hi·ªán t·∫°i: 0.7
Gain frame tr∆∞·ªõc: 0.9
‚Üí Kh√¥ng cho drop xu·ªëng 0.7 ngay
‚Üí Cho ph√©p t·ªëi ƒëa: 0.9 √ó 0.6 = 0.54
‚Üí Actual gain: max(0.7, 0.54) = 0.7 ‚úÖ

(Minimum decay rate = 0.6/frame = RT60 of 135ms)
```

**K·ªπ thu·∫≠t ƒë·∫∑c bi·ªát:** Energy compensation

- N·∫øu signal tƒÉng ƒë·ªôt ng·ªôt (transient) ‚Üí ƒëi·ªÅu ch·ªânh threshold
- Tr√°nh leak noise khi c√≥ transient

**K·∫øt qu·∫£:** Gains thay ƒë·ªïi t·ª± nhi√™n, kh√¥ng c√≥ artifacts

---

### **B∆∞·ªõc 9: Apply Gains - √Åp D·ª•ng L√™n Spectrum**

**L√†m g√¨:** Nh√¢n spectrum v·ªõi gains

**Chi ti·∫øt:**

1. **Interpolate:** 22 gains ‚Üí 241 gains (cho t·ª´ng bin)
2. **Multiply:** `spectrum[i] = spectrum[i] √ó gain[i]`

**QUAN TR·ªåNG - Phase Preservation:**

```
Complex spectrum = Magnitude √ó e^(i√óPhase)

Ch·ªâ nh√¢n magnitude:
new_spectrum = (Magnitude √ó gain) √ó e^(i√óPhase)
                ‚Üë Modified      ‚Üë GI·ªÆ NGUY√äN!
```

**T·∫°i sao gi·ªØ phase:**

- Phase r·∫•t kh√≥ predict ch√≠nh x√°c
- Magnitude-only modification = √≠t artifacts
- Phase ch·ª©a th√¥ng tin speech quan tr·ªçng

**K·∫øt qu·∫£:** Spectrum v·ªõi noise suppressed, phase preserved

---

### **B∆∞·ªõc 10: IFFT + Overlap-Add - T·ªïng H·ª£p**

**L√†m g√¨:** Chuy·ªÉn spectrum v·ªÅ time-domain

**IFFT:** 241 frequency bins ‚Üí 480 time samples

**Overlap-Add:**

```
Frame hi·ªán t·∫°i: [====240====][====240====]
Frame tr∆∞·ªõc:              [====240====][====240====]
                          ‚Üë Overlap 50%

C·ªông 2 overlap regions l·∫°i
‚Üí Smooth transition kh√¥ng c√≥ "seam"
```

**Window again:** Nh√¢n Hamming window l·∫ßn n·ªØa

**Output:** 480 samples denoised audio!

---

## Visual Flow - To√†n C·∫£nh

```
üé§ Raw Audio (10ms, noisy)
    ‚Üì
üîß High-Pass Filter ‚Üí B·ªè DC + rumble
    ‚Üì
ü™ü Windowing ‚Üí L√†m m∆∞·ª£t bi√™n
    ‚Üì
üìä FFT ‚Üí 241 frequency bins
    ‚Üì         ‚Üì
üéµ Pitch    üìà Band Energy
   (7 feat)    (22 feat)
    ‚Üì         ‚Üì
üîó Combine v·ªõi Correlation (6) + Delta (7)
    ‚Üì
‚ú® 42 Features (expert-designed)
    ‚Üì
üß† GRU Neural Network
   (Context-aware prediction)
    ‚Üì
üéöÔ∏è 22 Gains + 1 VAD
    ‚Üì
üéº Pitch Enhancement
    ‚Üì
‚è±Ô∏è Temporal Smoothing
    ‚Üì
‚úñÔ∏è Apply Gains (magnitude only)
    ‚Üì
üîÑ IFFT + Overlap-Add
    ‚Üì
üéß Clean Audio (10ms)
```

---

## Nh·ªØng ƒêi·ªÉm "Si√™u Hay Ho"

### 1. **Hybrid Approach (DSP + AI)**

Kh√¥ng ph·∫£i "pure deep learning":

- **DSP part:** Feature extraction (42 features)
  - Expert knowledge 30+ nƒÉm
  - Bark scale, pitch detection, correlation...
- **AI part:** GRU prediction
  - H·ªçc t·ª´ data
  - Context awareness

**K·∫øt h·ª£p t·ªët nh·∫•t 2 th·∫ø gi·ªõi!**

---

### 2. **Perceptual Compression**

```
241 bins ‚Üí 42 features = 83% compression!

Nh∆∞ng kh√¥ng m·∫•t th√¥ng tin quan tr·ªçng v√¨:
- Bark scale = theo tai ng∆∞·ªùi
- Pitch = c·ªët l√µi c·ªßa speech
- Correlation = temporal pattern
- Delta = dynamics
```

**Brilliant:** Compress theo c√°ch "c√≥ √Ω nghƒ©a"

---

### 3. **Minimum Gain = 0.6**

Never suppress below 60%!

**T·∫°i sao:**

- Tr√°nh "over-suppression" (gi·∫øt c·∫£ speech)
- 40% noise reduction ƒë√£ ƒë·ªß t·ªët
- Preserves speech naturalness

**Trade-off th√¥ng minh:** Ch·∫•p nh·∫≠n 1 ch√∫t noise c√≤n s√≥t, ƒë·ªïi l·∫°i speech t·ª± nhi√™n

---

### 4. **Lookahead = 1 Frame**

Process "delayed" spectrum (t·ª´ frame tr∆∞·ªõc):

```
Input frame N ‚Üí Extract features
             ‚Üí Predict gains for frame N-1
             ‚Üí Output frame N-1

Delay: 10ms
```

**T·∫°i sao:** C√≥ context t·ª´ future ‚Üí better decisions

**Acceptable:** 10ms latency kh√¥ng perceptible trong voice calls

---

### 5. **Stateful Processing**

GRU hidden state persists:

```
Frame 1 ‚Üí GRU state 1
       ‚Üì
Frame 2 ‚Üí GRU state 2 (affected by state 1)
       ‚Üì
Frame 3 ‚Üí GRU state 3 (affected by state 2)
```

**Power:** Hi·ªÉu "c√¢u chuy·ªán" c·ªßa audio, kh√¥ng ch·ªâ snapshot

---

### 6. **Energy Compensation**

Khi energy tƒÉng ƒë·ªôt ng·ªôt:

```
Energy[t-1] = 10
Energy[t] = 100  (transient!)

Na√Øve threshold: Fixed
Smart threshold: Adjust based on energy change

‚Üí Prevents noise leakage during transients
```

**Subtle nh∆∞ng crucial** cho quality!

---

## So S√°nh Tri·∫øt L√Ω

### **RNNoise Philosophy:**

```
"ƒê·ª´ng c·ªë ho√†n h·∫£o. C·ªë ƒë·ªß t·ªët + ƒë·ªß nhanh."

- Magnitude-only (b·ªè phase)
- 22 bands (kh√¥ng ph·∫£i 241 bins)
- Minimum gain 0.6 (kh√¥ng zero)
- 10ms latency (real-time)

‚Üí Engineering pragmatism ‚≠ê
```

### **U-Net Philosophy:**

```
"H·ªçc t·∫•t c·∫£ t·ª´ data. T√°i t·∫°o ho√†n h·∫£o."

- Full spectrogram reconstruction
- 26,624 values processed
- No domain knowledge constraints
- Quality > speed

‚Üí Academic perfectionism üéì
```

**Kh√¥ng c√≥ ƒë√∫ng sai, ch·ªâ c√≥ ph√π h·ª£p hay kh√¥ng!**

---

## Metrics Th·ª±c T·∫ø

**Per-frame processing:**

- Feature extraction: ~0.5ms
- GRU inference: ~2-5ms (SIMD optimized)
- Gain + IFFT: ~1ms
- **Total**: ~4-7ms

**V·ªõi input 10ms ‚Üí processing 7ms ‚Üí c√≤n 3ms buffer ‚Üí Real-time ‚úÖ**

**Memory:**

- Model: 85KB-1.5MB (t√πy version)
- State: ~20KB
- Buffers: ~10KB
- **Total**: ~30KB + model

**ESP32-S3:** ~10-15ms/frame (v·∫´n real-time!)

---

## Takeaways

1. **Expert features > Raw data** (trong constrained environments)
2. **Magnitude-only = pragmatic** (phase too hard)
3. **Temporal smoothing = essential** (avoid artifacts)
4. **Hybrid DSP+AI = powerful** (best of both)
5. **Perceptual design = efficient** (Bark scale, pitch...)

RNNoise = **Engineering masterpiece** trong real-time audio processing! üéØ
